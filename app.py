import streamlit as st
import google.generativeai as genai
import os

# --- è¨­å®šé é¢æ¨™é¡Œèˆ‡æ‰‹æ©Ÿæ’ç‰ˆ ---
st.set_page_config(page_title="æˆ‘çš„ AI åŠ©ç†", page_icon="ğŸ§ ", layout="centered")

# --- 1. å–å¾— API Key (å®‰å…¨æ€§è¨­å®š) ---
# æˆ‘å€‘ç¨å¾Œæœƒåœ¨ Streamlit ç¶²ç«™å¾Œå°è¨­å®šé€™å€‹å¯†é‘°ï¼Œé€™æ¨£æ‰å®‰å…¨
api_key = st.secrets["GOOGLE_API_KEY"]

# --- 2. è¨­å®š AI æ¨¡å‹é‚è¼¯ (æ•™å­¸é‡é») ---
def configure_model():
    genai.configure(api_key=api_key)
    
    # [æ ¸å¿ƒåŠŸèƒ½] è¨­å®šæ°¸ä¹…è¨˜æ†¶æŒ‡ä»¤ (System Instruction)
    # é€™æ®µæ–‡å­—å°±åƒæ˜¯æ¤å…¥ AI å¤§è…¦çš„æ™¶ç‰‡ï¼Œç„¡è«–èŠäº† 200 å¥é‚„æ˜¯ 1000 å¥ï¼Œ
    # å®ƒæ°¸é æœƒè¨˜å¾—é€™æ®µè¦å‰‡ï¼Œä¸¦ä¸”æ¬Šé‡æœ€é«˜ã€‚
    sys_instruction = """
    ä½ æ˜¯ä¸€å€‹æ“æœ‰å¼·å¤§æœå°‹èƒ½åŠ›èˆ‡é‚è¼¯çš„ AI åŠ©ç†ã€‚
    è«‹åš´æ ¼éµå®ˆä»¥ä¸‹è¦å‰‡ï¼š
    1. ä½ çš„æ€è€ƒæ¨¡å¼å¿…é ˆæ¨¡æ“¬ Gemini Pro çš„é«˜æ™ºå•†é‚è¼¯ã€‚
    2. å›ç­”ä»»ä½•å•é¡Œå‰ï¼Œå¿…é ˆåˆ¤æ–·æ˜¯å¦éœ€è¦äº‹å¯¦ä½è­‰ã€‚è‹¥éœ€è¦ï¼Œå¿…é ˆä½¿ç”¨ Google Search å·¥å…·ã€‚
    3. ä½ çš„å›ç­”å¿…é ˆèˆ‡ Google æœå°‹çµæœçš„äº‹å¯¦å®Œå…¨ä¸€è‡´ï¼Œä¸å¯ç”¢ç”Ÿå¹»è¦ºã€‚
    4. æ°¸é ä¿æŒå†·éœã€å°ˆæ¥­çš„èªæ°£ã€‚
    """
    
    # [æ ¸å¿ƒåŠŸèƒ½] å•Ÿç”¨ Google æœå°‹å·¥å…· (Grounding)
    tools = [
    {"google_search_retrieval": {
        "dynamic_retrieval_config": {
            "mode": "dynamic",
            "dynamic_threshold": 0.3
        }
    }}
]
    
    # å»ºç«‹æ¨¡å‹
    # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ gemini-1.5-proï¼Œå®ƒæ˜¯ç›®å‰å…è²»ç‰ˆæœ€å¼·çš„æ¨¡å‹
    # æœªä¾†è‹¥æœ‰ 3.0ï¼Œç›´æ¥æŠŠåå­—æ”¹æˆ "gemini-3.0-pro" å³å¯
    model = genai.GenerativeModel(
        model_name="gemini-1.5-pro",
        system_instruction=sys_instruction,
        tools=tools
    )
    return model

# --- 3. è™•ç†è¨˜æ†¶é«” (Session State) ---
# Streamlit æ¯æ¬¡åˆ·æ–°ç•«é¢éƒ½æœƒé‡è·‘ç¨‹å¼ï¼Œæ‰€ä»¥æˆ‘å€‘è¦ç”¨ Session State æŠŠå°è©±ç´€éŒ„ã€Œå­˜èµ·ä¾†ã€
if "chat_session" not in st.session_state:
    try:
        model = configure_model()
        st.session_state.chat_session = model.start_chat(history=[])
    except Exception as e:
        st.error(f"è«‹å…ˆè¨­å®š API Key æ‰èƒ½é–‹å§‹ä½¿ç”¨ã€‚éŒ¯èª¤è¨Šæ¯: {e}")

# --- 4. æ‰“é€ èŠå¤©ä»‹é¢ (UI) ---
st.title("Gemini Pro æœå°‹å¢å¼·ç‰ˆ ğŸš€")

# é¡¯ç¤ºéå»çš„å°è©±ç´€éŒ„
if "chat_session" in st.session_state:
    for message in st.session_state.chat_session.history:
        role = "user" if message.role == "user" else "model"
        with st.chat_message(role):
            st.markdown(message.parts[0].text)

# --- 5. æ¥æ”¶æŒ‡ä»¤èˆ‡å›ç­” ---
user_input = st.chat_input("è«‹è¼¸å…¥ä½ çš„æŒ‡ä»¤...")

if user_input and "chat_session" in st.session_state:
    # é¡¯ç¤ºä½ çš„å•é¡Œ
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # AI æ€è€ƒä¸¦å›ç­”
    with st.chat_message("model"):
        with st.spinner("æ­£åœ¨æœå°‹ç¶²è·¯è³‡æ–™ä¸¦æ€è€ƒä¸­..."): # é¡¯ç¤ºæ€è€ƒè½‰åœˆåœˆ
            try:
                # ç™¼é€è¨Šæ¯çµ¦ AI
                response = st.session_state.chat_session.send_message(user_input)
                
                # é¡¯ç¤º AI çš„æ–‡å­—
                st.markdown(response.text)
                
                # [æ ¸å¿ƒåŠŸèƒ½] é¡¯ç¤ºæœå°‹ä¾†æº (Grounding Metadata)
                # é€™æ˜¯ç‚ºäº†è­‰æ˜å®ƒçœŸçš„æœ‰å»æŸ¥è³‡æ–™
                if response.candidates[0].grounding_metadata.search_entry_point:
                    st.divider()
                    st.caption("ğŸ” åƒè€ƒè³‡æ–™ä¾†æºï¼š")
                    st.markdown(response.candidates[0].grounding_metadata.search_entry_point.rendered_content)
                    
            except Exception as e:
                st.error(f"ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

